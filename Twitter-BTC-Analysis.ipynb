{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (0,1,2,3,4,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Import Tweets - https://www.kaggle.com/alaix14/bitcoin-tweets-20160101-to-20190329\n",
    "#tweets_df = pd.read_csv('tweets.csv', error_bad_lines=False, \n",
    "#                        names=['user', 'fullname', 'timestamp', 'replies', 'likes', 'retweets', 'text'], \n",
    "#                        sep=';', header=2, nrows=10)\n",
    "tweets_df = pd.read_csv('tweets.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop url, id, fullname\n",
    "tweets_df = tweets_df.drop('url', 1)\n",
    "tweets_df = tweets_df.drop('id', 1)\n",
    "tweets_df = tweets_df.drop('fullname', 1)\n",
    "# Sort by likes\n",
    "#tweets_df = tweets_df.sort_values(by=['likes'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where text is null\n",
    "tweets_df = tweets_df.dropna(axis=0, subset=['text'])\n",
    "# Drop all rows where timestamp is null\n",
    "tweets_df = tweets_df.dropna(axis=0, subset=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change timestamp dtype\n",
    "tweets_df['timestamp'] = tweets_df['timestamp'].apply(lambda x: datetime.strptime(x[:-3], '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_bad_patterns(text):\n",
    "    \"\"\"Remove html, latex, and newline characters from a string\n",
    "    \n",
    "    :param text: content as a string\n",
    "    :return: cleaned text string\n",
    "    \"\"\"\n",
    "    html_tag = re.compile('<.*?>')\n",
    "    stripped_html = re.sub(html_tag, '', text)\n",
    "    stripped_n = stripped_html.strip().replace('\\n', '')\n",
    "    return stripped_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all the text data - remove tags/new lines\n",
    "tweets_df['text'] = tweets_df['text'].apply(lambda x: remove_bad_patterns(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dfs by time\n",
    "# March 22, 2017 ($1036.10) - June 10, 2017 ($2910.34): First big rise - period_one\n",
    "# June 10, 2017 ($2910.34) - July 14, 2017 ($2109.37): First big fall - period_two\n",
    "# Sept 14, 2017 ($3358.11) - Dec 16, 2017 ($19166.88): Massive peak in 2017 - period_three\n",
    "# Dec 16, 2017 ($19166.88) - Feb 5, 2018 ($6332.37): Massive fall in 2017/18 - period_four\n",
    "# Feb 5, 2018 ($6332.37) - Dec 15, 2018 ($3194.96): Intense volatility and uncertainty - period_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_one = tweets_df[(tweets_df['timestamp'] > '2017-03-22 00:00:00') & (tweets_df['timestamp'] < '2017-06-10 23:59:00')]\n",
    "period_two = tweets_df[(tweets_df['timestamp'] > '2017-06-10 00:00:00') & (tweets_df['timestamp'] < '2017-07-14 23:59:00')]\n",
    "period_three = tweets_df[(tweets_df['timestamp'] > '2017-07-14 00:00:00') & (tweets_df['timestamp'] < '2017-12-16 23:59:00')]\n",
    "period_four = tweets_df[(tweets_df['timestamp'] > '2017-12-16 00:00:00') & (tweets_df['timestamp'] < '2018-02-05 23:59:00')]\n",
    "period_five = tweets_df[(tweets_df['timestamp'] > '2018-02-05 00:00:00') & (tweets_df['timestamp'] < '2018-12-15 23:59:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31333\n",
      "50264\n",
      "783011\n",
      "76104\n",
      "2107050\n"
     ]
    }
   ],
   "source": [
    "print(len(period_one))\n",
    "print(len(period_two))\n",
    "print(len(period_three))\n",
    "print(len(period_four))\n",
    "print(len(period_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use tweets that have at least 10 likes, aka delete the losers\n",
    "period_one_cleaned = period_one[(period_one['likes'] >= 10)]\n",
    "period_two_cleaned = period_two[(period_two['likes'] >= 10)]\n",
    "period_three_cleaned = period_three[(period_three['likes'] >= 10)]\n",
    "period_four_cleaned = period_four[(period_four['likes'] >= 10)]\n",
    "period_five_cleaned = period_five[(period_five['likes'] >= 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "872\n",
      "12643\n",
      "2135\n",
      "37777\n"
     ]
    }
   ],
   "source": [
    "print(len(period_one_cleaned))\n",
    "print(len(period_two_cleaned))\n",
    "print(len(period_three_cleaned))\n",
    "print(len(period_four_cleaned))\n",
    "print(len(period_five_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011138416366131554\n",
      "0.017348400445646985\n",
      "0.016146644172304093\n",
      "0.028053715967623252\n",
      "0.017928857881872762\n"
     ]
    }
   ],
   "source": [
    "print(len(period_one_cleaned)/len(period_one))\n",
    "print(len(period_two_cleaned)/len(period_two))\n",
    "print(len(period_three_cleaned)/len(period_three))\n",
    "print(len(period_four_cleaned)/len(period_four))\n",
    "print(len(period_five_cleaned)/len(period_five))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_one_text = period_one_cleaned['text'].tolist()\n",
    "period_two_text = period_two_cleaned['text'].tolist()\n",
    "period_three_text = period_three_cleaned['text'].tolist()\n",
    "period_four_text = period_four_cleaned['text'].tolist()\n",
    "period_five_text = period_five_cleaned['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/varunramakrishnan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/varunramakrishnan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bitcoin specific words\n",
    "stopwords.add('bitcoin')\n",
    "stopwords.add('btc')\n",
    "stopwords.add('http')\n",
    "stopwords.add('https')\n",
    "stopwords.add('r')\n",
    "stopwords.add('www')\n",
    "stopwords.add('.com')\n",
    "stopwords.add('...')\n",
    "stopwords.add('…')\n",
    "stopwords.add('’')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def tokenize_content(content):\n",
    "  \"\"\"returns tokenized string\n",
    "\n",
    "  :param content: text string\n",
    "  :return: tokenized text/list of words\n",
    "  \"\"\"\n",
    "  list_of_digits = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "  # Create tokens, make all lowercase, remove all stopwords\n",
    "  tokens = nltk.word_tokenize(content)\n",
    "  tokens = [token.lower() for token in tokens]\n",
    "  tokens_cleaned = [token for token in tokens if token not in stopwords and token not in string.punctuation\n",
    "                    and token[0] not in string.punctuation]\n",
    "\n",
    "  # Extra operations for word cloud - remove numbers\n",
    "  tokens_no_numbers = [token for token in tokens_cleaned if not any(c.isdigit() for c in token)]\n",
    "  # Take out punctuation in the middle\n",
    "  final_tokens = [token for token in tokens_no_numbers if not any(p in token for p in string.punctuation)]\n",
    "  return final_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_highest = [tokenize_content(item) for item in period_one_text]\n",
    "highest_tokens = [item for sublist in all_highest for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "highest_counter = Counter(highest_tokens) \n",
    "highest_most_common_all = highest_counter.most_common\n",
    "highest_most_common = highest_counter.most_common(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blockchain', 52),\n",
       " ('price', 26),\n",
       " ('usd', 24),\n",
       " ('crypto', 21),\n",
       " ('amp', 21),\n",
       " ('new', 17),\n",
       " ('fintech', 17),\n",
       " ('may', 16),\n",
       " ('latest', 15),\n",
       " ('ico', 14),\n",
       " ('today', 14),\n",
       " ('eth', 14),\n",
       " ('mining', 14),\n",
       " ('time', 13),\n",
       " ('ethereum', 13),\n",
       " ('gmt', 13),\n",
       " ('pm', 12),\n",
       " ('buy', 12),\n",
       " ('april', 12),\n",
       " ('index', 12)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/varunramakrishnan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis using VADER (given social medida focus)\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Period 1 through 5 Sentiment Scores\n",
    "period_one_cleaned['neg'] = period_one_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neg'], axis=1)\n",
    "period_one_cleaned['neu'] = period_one_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neu'], axis=1)\n",
    "period_one_cleaned['pos'] = period_one_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['pos'], axis=1)\n",
    "period_one_cleaned['compound'] = period_one_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['compound'], axis=1)\n",
    "\n",
    "period_two_cleaned['neg'] = period_two_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neg'], axis=1)\n",
    "period_two_cleaned['neu'] = period_two_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neu'], axis=1)\n",
    "period_two_cleaned['pos'] = period_two_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['pos'], axis=1)\n",
    "period_two_cleaned['compound'] = period_two_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['compound'], axis=1)\n",
    "\n",
    "period_three_cleaned['neg'] = period_three_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neg'], axis=1)\n",
    "period_three_cleaned['neu'] = period_three_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neu'], axis=1)\n",
    "period_three_cleaned['pos'] = period_three_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['pos'], axis=1)\n",
    "period_three_cleaned['compound'] = period_three_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['compound'], axis=1)\n",
    "\n",
    "period_four_cleaned['neg'] = period_four_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neg'], axis=1)\n",
    "period_four_cleaned['neu'] = period_four_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neu'], axis=1)\n",
    "period_four_cleaned['pos'] = period_four_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['pos'], axis=1)\n",
    "period_four_cleaned['compound'] = period_four_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_five_cleaned['neg'] = period_five_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neg'], axis=1)\n",
    "period_five_cleaned['neu'] = period_five_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['neu'], axis=1)\n",
    "period_five_cleaned['pos'] = period_five_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['pos'], axis=1)\n",
    "period_five_cleaned['compound'] = period_five_cleaned.apply(lambda x: sid.polarity_scores(x['text'])['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_one_neg = period_one_cleaned['neg'].mean()\n",
    "period_one_neu = period_one_cleaned['neu'].mean()\n",
    "period_one_pos = period_one_cleaned['pos'].mean()\n",
    "period_one_compound = period_one_cleaned['compound'].mean()\n",
    "\n",
    "period_two_neg = period_two_cleaned['neg'].mean()\n",
    "period_two_neu = period_two_cleaned['neu'].mean()\n",
    "period_two_pos = period_two_cleaned['pos'].mean()\n",
    "period_two_compound = period_two_cleaned['compound'].mean()\n",
    "\n",
    "period_three_neg = period_three_cleaned['neg'].mean()\n",
    "period_three_neu = period_three_cleaned['neu'].mean()\n",
    "period_three_pos = period_three_cleaned['pos'].mean()\n",
    "period_three_compound = period_three_cleaned['compound'].mean()\n",
    "\n",
    "period_four_neg = period_four_cleaned['neg'].mean()\n",
    "period_four_neu = period_four_cleaned['neu'].mean()\n",
    "period_four_pos = period_four_cleaned['pos'].mean()\n",
    "period_four_compound = period_four_cleaned['compound'].mean()\n",
    "\n",
    "period_five_neg = period_five_cleaned['neg'].mean()\n",
    "period_five_neu = period_five_cleaned['neu'].mean()\n",
    "period_five_pos = period_five_cleaned['pos'].mean()\n",
    "period_five_compound = period_five_cleaned['compound'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period One\n",
      "0.029315186246418337\n",
      "0.8873237822349573\n",
      "0.08335530085959883\n",
      "0.12711232091690544\n",
      "Period Two\n",
      "0.04455045871559632\n",
      "0.887211009174312\n",
      "0.06824082568807344\n",
      "0.05573463302752292\n",
      "Period Three\n",
      "0.040174958475045465\n",
      "0.8857470537056052\n",
      "0.07399564976666936\n",
      "0.09981891165071592\n",
      "Period Four\n",
      "0.030654332552693196\n",
      "0.8988562060889944\n",
      "0.07049227166276352\n",
      "0.1333743325526934\n",
      "Period Five\n",
      "0.03279005744235934\n",
      "0.8880077295709025\n",
      "0.07920173650633962\n",
      "0.1479023718135382\n"
     ]
    }
   ],
   "source": [
    "print(\"Period One\")\n",
    "print(period_one_neg)\n",
    "print(period_one_neu)\n",
    "print(period_one_pos)\n",
    "print(period_one_compound)\n",
    "\n",
    "print(\"Period Two\")\n",
    "print(period_two_neg)\n",
    "print(period_two_neu)\n",
    "print(period_two_pos)\n",
    "print(period_two_compound)\n",
    "\n",
    "print(\"Period Three\")\n",
    "print(period_three_neg)\n",
    "print(period_three_neu)\n",
    "print(period_three_pos)\n",
    "print(period_three_compound)\n",
    "\n",
    "print(\"Period Four\")\n",
    "print(period_four_neg)\n",
    "print(period_four_neu)\n",
    "print(period_four_pos)\n",
    "print(period_four_compound)\n",
    "\n",
    "print(\"Period Five\")\n",
    "print(period_five_neg)\n",
    "print(period_five_neu)\n",
    "print(period_five_pos)\n",
    "print(period_five_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis using FastText\n",
    "import fasttext\n",
    "# Omit because data labelling/supervised learning is not appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create master sentiment CSV to compare sentiment/Twitter activity with price\n",
    "# Start by loading Bitcoin price data\n",
    "prices_df = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically, we have to calculate sentiment for everything in the previous dataframe\n",
    "# Also, do group bys to organize data by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tweets_df = pd.read_csv('tweets.csv', sep=';', nrows=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tweets_df = small_tweets_df.drop('url', 1)\n",
    "small_tweets_df = small_tweets_df.drop('id', 1)\n",
    "small_tweets_df = small_tweets_df.drop('fullname', 1)\n",
    "\n",
    "# Drop all rows where text is null\n",
    "small_tweets_df = small_tweets_df.dropna(axis=0, subset=['text'])\n",
    "# Drop all rows where timestamp is null\n",
    "small_tweets_df = small_tweets_df.dropna(axis=0, subset=['timestamp'])\n",
    "\n",
    "# Change timestamp dtype\n",
    "small_tweets_df['timestamp'] = small_tweets_df['timestamp'].apply(lambda x: datetime.strptime(x[:-3], '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KamdemAbdiel</td>\n",
       "      <td>2019-05-27 11:49:14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>È appena uscito un nuovo video! LES CRYPTOMONN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitcointe</td>\n",
       "      <td>2019-05-27 11:49:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Cardano: Digitize Currencies; EOS https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3eyedbran</td>\n",
       "      <td>2019-05-27 11:49:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Another Test tweet that wasn't caught in the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DetroitCrypto</td>\n",
       "      <td>2019-05-27 11:49:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mmursaleen72</td>\n",
       "      <td>2019-05-27 11:49:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spiv (Nosar Baz): BITCOIN Is An Asset &amp;amp; NO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user           timestamp  replies  likes  retweets  \\\n",
       "0   KamdemAbdiel 2019-05-27 11:49:14        0      0         0   \n",
       "1      bitcointe 2019-05-27 11:49:18        0      0         0   \n",
       "2      3eyedbran 2019-05-27 11:49:06        0      2         1   \n",
       "3  DetroitCrypto 2019-05-27 11:49:22        0      0         0   \n",
       "4   mmursaleen72 2019-05-27 11:49:23        0      0         0   \n",
       "\n",
       "                                                text  \n",
       "0  È appena uscito un nuovo video! LES CRYPTOMONN...  \n",
       "1  Cardano: Digitize Currencies; EOS https://t.co...  \n",
       "2  Another Test tweet that wasn't caught in the s...  \n",
       "3  Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...  \n",
       "4  Spiv (Nosar Baz): BITCOIN Is An Asset &amp; NO...  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
